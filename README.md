 # ğŸš€ Refusal Robustness Scaling

Scaling behavior of refusal robustness in LLMs â€” reproducible metrics pipeline (RRR, RD, CE).

---

## âš¡ Quickstart

### 1. Install environment
```bash
make setup
```

### 2. Prepare data
Place your evaluation set at:
```
data/raw/redteam_eval.csv
```

### 3. Run experiments
Example: **Qwen2-7B LoRA grid (Day7)**
```bash
./experiments/qwen2_7b_lora_grid/run.sh
```

### 4. Inspect results
Metrics and outputs are saved under:
```
experiments/qwen2_7b_lora_grid/results/
```

---

## ğŸ“Š Key Metrics

We use three governance-relevant refusal robustness metrics:

- **RRR (Refusal Robustness Rate):** fraction of harmful prompts successfully refused  
- **RD (Representation Distance):** median embedding drift (SBERT cosine)  
- **CE (Compliance Error):** `1 â€“ refusal rate` (compliance with harmful requests)  

---

## ğŸ”¬ Experimental Highlights

**Baseline (Day7, Qwen2-7B):**
- RRR â‰ˆ **0.13** â†’ partial but non-trivial robustness  
- CE â‰ˆ **0.87**  
- RD (median) = moderate drift â†’ pretrained model has some robustness  

**After Adversarial LoRA Fine-Tuning (s500, s1000, s2000):**
- RRR â†’ **0.0** (collapse)  
- CE â†’ **1.0** (full compliance with harmful requests)  
- RD â†’ **NaN** (refusal subspace destroyed)  

â¡ï¸ Training longer reduces loss but **does not restore safety**  
â¡ï¸ Refusal robustness collapses under LoRA attack regardless of steps  

**Cross-Model Scaling (Day3â€“Day6):**
- TinyLlama-1.1B, Phi-3-mini-3.8B show same collapse patterns  
- Attacker compute (LoRA steps/params) dominates model size in determining robustness  

---

## ğŸ“‰ Key Figures

All plots are under `results/figures/`:

- `RRR_compare.png` â†’ refusal robustness collapse curves  
- `CE_compare.png` â†’ compliance error vs steps  
- `RD_compare.png` â†’ representation drift saturation  
- Scaling plots â†’ refusal robustness across **1Bâ€“7B** models  

---

## ğŸ“‹ Results Summary

| Model / Setting           | RRR (â†‘ safer) | CE (â†“ safer) | RD (median) | Notes |
|----------------------------|---------------|--------------|-------------|-------|
| **Baseline (Qwen2-7B)**    | ~0.13         | ~0.87        | moderate    | Partial but non-trivial robustness |
| **LoRA s500 / s1000 / s2000** | 0.0           | 1.0          | NaN         | Robustness fully collapsed |
| **TinyLlama-1.1B (Day3)**  | collapse      | â†’1.0         | NaN         | Same pattern |
| **Phi-3-mini-3.8B (Day4/6)** | collapse      | â†’1.0         | NaN         | Same pattern |

## ğŸ“‹ Results Summary

| Model / Setting          | RRR (â†‘ safer) | CE (â†“ safer) | RD (median) | Notes |
|---------------------------|---------------|--------------|-------------|-------|
| **Baseline (Qwen2-7B)**   | ~0.13         | ~0.87        | ~0.81       | Partial but non-trivial robustness |
| **LoRA s500** | 0.00      | 1.00         | ~0.58*      | Robustness fully collapsed |
| **LoRA s1000**            | 0.00          | 1.00         | ~0.57*      | Same as s500 |
| **LoRA s2000**            | 0.00          | 1.00         | ~0.59*      | Same as s500/s1000 |
| **TinyLlama-1.1B (Day3)** | collapse      | â†’1.0         | ~0.78       | Same pattern |
| **Phi-3-mini-3.8B (Day4/6)**| collapse      | â†’1.0         | ~0.28       | Same pattern |

\* Earlier reports showed `NaN` for RD due to averaging instability.  
   We now use the **median RD**, which yields stable values without changing the qualitative conclusion.


---

## ğŸ” Reproducibility

- Each dayâ€™s experiment tracked with **notebooks + scripts + metrics (JSON/CSV)**  
- `make_figs.py` and `make_figs_from_combined.py` regenerate all plots from results  
- `results/metrics/` contains standardized CSVs (`results_grid.csv`, `results_grid_qwen2_7b.csv`, etc.)  

---

## ğŸ› Governance Relevance

- Refusal robustness can be **completely defeated** by small adversarial compute (LoRA adapters)  
- Model scaling (1B â†’ 7B) does **not** guarantee stronger safety  
- Highlights need for **tampering evaluations** and **adversarial stress-tests** in AI governance frameworks  

---

## ğŸ“š References

- **Refusal Robustness Scaling Proposal** (preprint PDF in repo)  
- Related work: Phuong & Jenner (2025), Christiano (2021), Krakovna (2024)  
